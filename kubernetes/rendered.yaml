---
# Source: hive/templates/hive-service-account.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: hive-service-account
---
# Source: hive/templates/master-service-account.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  namespace: default
  name: master-service-account
---
# Source: hive/templates/worker-service-account.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  namespace: default
  name: worker-service-account
---
# Source: hive/templates/env-secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: env-secret
type: Opaque
data:
  data:
  env-secret.sh: IyEvYmluL2Jhc2gKCiMgTGljZW5zZWQgdW5kZXIgdGhlIEFwYWNoZSBMaWNlbnNlLCBWZXJzaW9uIDIuMCAodGhlICJMaWNlbnNlIik7CiMgeW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgojIFlvdSBtYXkgb2J0YWluIGEgY29weSBvZiB0aGUgTGljZW5zZSBhdAojCiMgICAgIGh0dHA6Ly93d3cuYXBhY2hlLm9yZy9saWNlbnNlcy9MSUNFTlNFLTIuMAojCiMgVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQojIGRpc3RyaWJ1dGVkIHVuZGVyIHRoZSBMaWNlbnNlIGlzIGRpc3RyaWJ1dGVkIG9uIGFuICJBUyBJUyIgQkFTSVMsCiMgV0lUSE9VVCBXQVJSQU5USUVTIE9SIENPTkRJVElPTlMgT0YgQU5ZIEtJTkQsIGVpdGhlciBleHByZXNzIG9yIGltcGxpZWQuCiMgU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAojIGxpbWl0YXRpb25zIHVuZGVyIHRoZSBMaWNlbnNlLgoKSElWRV9TRVJWRVIyX1NTTF9UUlVTVFNUT1JFUEFTUz0KZXhwb3J0IEhBRE9PUF9DUkVEU1RPUkVfUEFTU1dPUkQ9CgojIEhlcmUgdGhlIHVzZXIgY2FuIGRlZmluZSBhZGRpdGlvbmFsIGVudmlyb25tZW50IHZhcmlhYmxlcyB1c2luZyAnRVhQT1JUJywgZS5nLjoKIyAgIGV4cG9ydCBGT089YmFyCgo=
---
# Source: hive/templates/hive-secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: hivemr3-keytab-secret
type: Opaque
data:
---
# Source: hive/templates/worker-secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: hivemr3-worker-secret
type: Opaque
data:
---
# Source: hive/templates/client-am-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: client-am-config
data:
  key: "f13b0a71-7813-4ed1-9996-462040c77b09"
  timestamp: "65450346"
  mr3sessionid: "bee9a7c8-a662-45f4-b2c5-1abb7a34b7c2"
  ats-secret-key: "dbcd0b25-6af7-411c-b1ca-6eb8a7071b68"
---
# Source: hive/templates/env-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: env-configmap
data:
  env.sh: "#!/bin/bash\n\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n#
    you may not use this file except in compliance with the License.\n# You may obtain
    a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n#
    Unless required by applicable law or agreed to in writing, software\n# distributed
    under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR
    CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific
    language governing permissions and\n# limitations under the License.\n\n#\n# Basic
    settings\n# \n\nREMOTE_BASE_DIR=/opt/mr3-run\nREMOTE_WORK_DIR=/opt/mr3-run/hive\nCONF_DIR_MOUNT_DIR=/opt/mr3-run/conf\n#
    for mr3.k8s.keytab.mount.dir\nKEYTAB_MOUNT_DIR=/opt/mr3-run/key\nWORK_DIR_PERSISTENT_VOLUME_CLAIM=workdir-pvc\nWORK_DIR_PERSISTENT_VOLUME_CLAIM_MOUNT_DIR=/opt/mr3-run/work-dir\n\n#
    JAVA_HOME and PATH are already set inside the container.\n\n# If USE_JAVA_17 is
    set to false,\n#\n#   1) update mr3.am.launch.cmd-opts and mr3.container.launch.cmd-opts
    in conf/mr3-site.xml.\n#     remove: -XX:+AggressiveOpts\n#\n# Cf. run-master.sh
    and run-worker.sh set \"--add-opens\".\n#\nexport USE_JAVA_17=true\n\n# HIVE_MR3_JVM_OPTION
    = JVM options for Metastore and HiveServer2\nif [[ $USE_JAVA_17 = false ]]; then\n
    \ HIVE_MR3_JVM_OPTION=\"-XX:+UseG1GC -XX:+ResizeTLAB -XX:+UseNUMA -server -Djava.net.preferIPv4Stack=true
    -XX:+AggressiveOpts\"\nelse\n  HIVE_MR3_JVM_OPTION=\"-XX:+UseG1GC -XX:+ResizeTLAB
    -XX:+UseNUMA -server -Djava.net.preferIPv4Stack=true\"\n  HIVE_MR3_JVM_OPTION=\"$HIVE_MR3_JVM_OPTION
    --add-opens java.base/java.lang=ALL-UNNAMED --add-opens java.base/java.net=ALL-UNNAMED
    --add-opens java.base/java.util=ALL-UNNAMED --add-opens java.base/java.time=ALL-UNNAMED
    --add-opens java.base/java.io=ALL-UNNAMED --add-opens java.base/java.util.concurrent=ALL-UNNAMED
    --add-opens java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens java.base/java.util.regex=ALL-UNNAMED
    --add-opens java.base/java.util.zip=ALL-UNNAMED --add-opens java.base/java.util.stream=ALL-UNNAMED
    --add-opens java.base/java.util.jar=ALL-UNNAMED --add-opens java.base/java.util.function=ALL-UNNAMED
    --add-opens java.logging/java.util.logging=ALL-UNNAMED --add-opens java.base/java.nio=ALL-UNNAMED
    --add-opens java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.lang.ref=ALL-UNNAMED
    --add-opens=java.base/java.nio.charset=ALL-UNNAMED --add-opens=java.base/java.text=ALL-UNNAMED
    --add-opens=java.base/java.util.concurrent.locks=ALL-UNNAMED\"\nfi\n\n#\n# Step
    1. Building a Docker image\n#\n\nDOCKER_HIVE_IMG=mr3project/hive3:1.9\nDOCKER_HIVE_WORKER_IMG=mr3project/hive3:1.9\n\nDOCKER_USER=hive\n\n#\n#
    Step 2. Configuring Pods\n#\n\nMR3_NAMESPACE=default\nMR3_SERVICE_ACCOUNT=hive-service-account\nCONF_DIR_CONFIGMAP=hivemr3-conf-configmap\n\nMASTER_SERVICE_ACCOUNT=master-service-account\nWORKER_SERVICE_ACCOUNT=worker-service-account\n\n#
    CREATE_KEYTAB_SECRET specifies whether or not to create a Secret from key/*.\n#
    CREATE_KEYTAB_SECRET should be set to true if any of the following holds:\n#   1)
    TOKEN_RENEWAL_HDFS_ENABLED=true\n#   2) TOKEN_RENEWAL_HIVE_ENABLED=true\n#   3)
    SSL is enabled\nCREATE_KEYTAB_SECRET=false\nKEYTAB_SECRET=hivemr3-keytab-secret\n\n#
    CREATE_WORKER_SECRET specifies whether or not to create a Secret for ContainerWorkers
    from $WORKER_SECRET_DIR.\n# CREATE_WORKER_SECRET is irrelevant to token renewal,
    and WORKER_SECRET_DIR is not requird to contain keytab files.\n# CREATE_WORKER_SECRET
    should be set to true if:\n#   - SSL is enabled\nCREATE_WORKER_SECRET=false\nWORKER_SECRET=hivemr3-worker-secret\n\n#\n#
    Step 3. Update YAML files\n#\n\n#\n# Step 4. Configuring HiveServer2 - connecting
    to Metastore\n#\n\n# HIVE_DATABASE_HOST = host for Metastore database \n# HIVE_METASTORE_HOST
    = host for Metastore itself \n# HIVE_METASTORE_PORT = port for Hive Metastore \n#
    HIVE_DATABASE_NAME = database name in Hive Metastore \n# HIVE_WAREHOUSE_DIR = directory
    for the Hive warehouse \n\nHIVE_DATABASE_HOST=mysql.hivemr3.svc.cluster.local\n\n#
    if an existing Metastore is used \n# HIVE_METASTORE_HOST=red0\n# if a new Metastore
    Pod is to be created inside K8s\nHIVE_METASTORE_HOST=hivemr3-metastore-0.metastore.default.svc.cluster.local\n\nHIVE_METASTORE_PORT=9850\nHIVE_DATABASE_NAME=hive5mr3\n\n#
    path to the data warehouse, e.g.,\n#   hdfs://foo:8020/user/hive/warehouse\n#   s3a://mr3-bucket/warehouse\n#
    \  /opt/mr3-run/work-dir/warehouse/\nHIVE_WAREHOUSE_DIR=s3a://blox-dev-use1-internal/hivemr3/warehouse\n\n#
    Specifies hive.metastore.sasl.enabled \nMETASTORE_SECURE_MODE=false\n\n#
    For security in Metastore \n# Kerberos principal for Metastore; cf. 'hive.metastore.kerberos.principal'
    in hive-site.xml\nHIVE_METASTORE_KERBEROS_PRINCIPAL=hive/red0@RED\n#
    Kerberos keytab for Metastore; cf. 'hive.metastore.kerberos.keytab.file' in hive-site.xml\nHIVE_METASTORE_KERBEROS_KEYTAB=$KEYTAB_MOUNT_DIR/hive.service.keytab\n\n#\n#
    Step 5. Configuring HiveServer2 - connecting to HiveServer2\n#\n\n# HIVE_SERVER2_PORT
    = thrift port for HiveServer2 (for both cluster mode and local mode)\n# HIVE_SERVER2_HTTP_PORT
    = http port for HiveServer2\n#\nHIVE_SERVER2_HOST=$HOSTNAME\nHIVE_SERVER2_PORT=9852\nHIVE_SERVER2_HTTP_PORT=10001\n\n#
    Heap size in MB for HiveServer2\n# With --local option, mr3.am.resource.memory.mb
    and mr3.am.local.resourcescheduler.max.memory.mb should be smaller. \nHIVE_SERVER2_HEAPSIZE=1000\n\n#
    For security in HiveServer2 \n# Beeline should also provide this Kerberos principal.\n#
    Authentication option: NONE (uses plain SASL), NOSASL, KERBEROS, LDAP, PAM, and
    CUSTOM; cf. 'hive.server2.authentication' in hive-site.xml \nHIVE_SERVER2_AUTHENTICATION=NONE\n#
    Kerberos principal for HiveServer2; cf. 'hive.server2.authentication.kerberos.principal'
    in hive-site.xml \nHIVE_SERVER2_KERBEROS_PRINCIPAL=hive/red0@RED\n#
    Kerberos keytab for HiveServer2; cf. 'hive.server2.authentication.kerberos.keytab'
    in hive-site.xml \nHIVE_SERVER2_KERBEROS_KEYTAB=$KEYTAB_MOUNT_DIR/hive.service.keytab\n\n#
    Specifies whether Hive token renewal is enabled inside DAGAppMaster and ContainerWorkers
    \nTOKEN_RENEWAL_HIVE_ENABLED=false\n\n# Truststore
    for HiveServer2\n# For Timeline Server, Ranger, see their configuration files\nHIVE_SERVER2_SSL_TRUSTSTORE=$KEYTAB_MOUNT_DIR/hivemr3-ssl-certificate.jks\nHIVE_SERVER2_SSL_TRUSTSTORETYPE=jks\n\n#\n#
    Step 6. Reading from a secure HDFS\n#\n\n# 1) for renewing HDFS/Hive tokens in DAGAppMaster
    (mr3.keytab in mr3-site.xml)\n# 2) for renewing HDFS/Hive tokens in ContainerWorker
    (mr3.k8s.keytab.mount.file in mr3-site.xml)\n\n# Kerberos principal for renewing
    HDFS/Hive tokens (Cf. mr3.principal)\nUSER_PRINCIPAL=hive@RED\n#
    Kerberos keytab (for mr3.keytab)\nUSER_KEYTAB=$KEYTAB_MOUNT_DIR/hive.keytab\n#
    for mr3.k8s.keytab.mount.file\nKEYTAB_MOUNT_FILE=hive.keytab\n\n#
    Specifies whether HDFS token renewal is enabled inside DAGAppMaster and ContainerWorkers
    \nTOKEN_RENEWAL_HDFS_ENABLED=false\n\n#\n# Step 7.
    Additional settings\n#\n\n# Logging level \nLOG_LEVEL=INFO\n\n#\n#
    For running Metastore\n#\n\n# Heap size in MB for Metastore\nHIVE_METASTORE_HEAPSIZE=8192\n\n#
    Type of Metastore database which is used when running 'schematool -initSchema'\nHIVE_METASTORE_DB_TYPE=mysql\n\n#\n#
    For running HiveCLI \n#\n\n# Heap size in MB for HiveCLI ('hive' command) \n# With
    --local option, mr3.am.resource.memory.mb and mr3.am.local.resourcescheduler.max.memory.mb
    should be smaller. \nHIVE_CLIENT_HEAPSIZE=16384\n\n# unset because 'hive' command
    reads SPARK_HOME and may accidentally expand the classpath with HiveConf.class from
    Spark. \nunset SPARK_HOME\n\n"
---
# Source: hive/templates/hive-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: hivemr3-conf-configmap
data:
  core-site.xml: |
    <configuration>
  
    <property>
      <name>fs.defaultFS</name>
      <value>file:///</value>
    </property>
  
    <property>
      <name>hadoop.security.authentication</name>
      <value>simple</value>
    </property>
  
    <property>
      <name>dfs.encryption.key.provider.uri</name>
      <value></value>
    </property>
  
    <property>
      <name>ipc.client.fallback-to-simple-auth-allowed</name>
      <value>true</value>
    </property>
  
    <!-- Cf. tez.runtime.shuffle.ssl.enable for secure shuffle in tez-site.xml -->
    <property>
      <name>hadoop.security.credential.provider.path</name>
      <value></value>
      <!-- <value>localjceks://file/opt/mr3-run/key/hivemr3-ssl-certificate.jceks</value> -->
    </property>
  
    <!--
      Upon the deletion of DAGAppMasterPod, HiveServer2 tries to connect to DAGAppMaster Pod at least twice
      and up to three times (acknowledgeDagFinished(), getEstimateNumTasksOrNodes(), getApplicationReport().
      Each wait takes 20 seconds, so HiveServer2 may wait 3 * ipc.client.connect.max.retries.on.timeouts * 20 seconds
      before creating a new DAGAppMaster Pod.
     -->
    <property>
      <name>ipc.client.connect.max.retries.on.timeouts</name>
      <value>3</value>
    </property>
  
    <!-- S3 -->
  
    <!-- set when using S3 or on AWS EKS -->
    <!-- options:
         com.amazonaws.auth.EnvironmentVariableCredentialsProvider
         com.amazonaws.auth.InstanceProfileCredentialsProvider
         com.amazonaws.auth.WebIdentityTokenCredentialsProvider -->
    <property>
      <name>fs.s3a.aws.credentials.provider</name>
      <value>com.amazonaws.auth.InstanceProfileCredentialsProvider</value>
    </property>
  
    <property>
      <name>fs.s3a.connection.ssl.enabled</name>
      <value>false</value>
    </property>
  
    <!-- set when using S3 -->
    <!-- do not set on AWS EKS -->
    <property>
      <name>fs.s3a.endpoint</name>
      <value></value>
    </property>
  
    <!-- set to true when using path-style access to S3-compliant storage -->
    <property>
      <name>fs.s3a.path.style.access</name>
      <value>true</value>
    </property>
  
    <property>
      <name>fs.s3a.impl</name>
      <value>org.apache.hadoop.fs.s3a.S3AFileSystem</value>
    </property>
  
    <property>
      <name>fs.s3a.connection.maximum</name>
      <value>4000</value>
    </property>
  
    <property>
      <name>fs.s3.maxConnections</name>
      <value>4000</value>
    </property>
  
    <property>
      <name>fs.s3a.threads.max</name>
      <value>250</value>
    </property>
  
    <property>
      <name>fs.s3a.threads.core</name>
      <value>250</value>
    </property>
  
    <!-- S3 write performance -->
  
    <property>
      <name>hive.mv.files.thread</name>
      <value>15</value>
    </property>
  
    <property>
      <name>fs.s3a.max.total.tasks</name>
      <value>5</value>
    </property>
  
    <property>
      <name>fs.s3a.blocking.executor.enabled</name>
      <value>false</value>
    </property>
  
    <!-- with HIVE-21390, the # of InputSplits is affected by hive.exec.orc.blob.storage.split.size
         when hive.exec.orc.split.strategy is set to BI -->
    <property>
      <name>fs.s3a.block.size</name>
      <value>128M</value>
    </property>
  
    <!-- S3 input listing (Cf. hive.exec.input.listing.max.threads) -->
    <property>
      <name>mapreduce.input.fileinputformat.list-status.num-threads</name>
      <value>50</value>
    </property>
  
    </configuration>
  hadoop-metrics2-s3a-file-system.properties: |
    *.period=180
  hive-log4j2.properties: "# Licensed under the Apache License, Version 2.0 (the \"License\");\n#
    you may not use this file except in compliance with the License.\n# You may obtain
    a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n#
    Unless required by applicable law or agreed to in writing, software\n# distributed
    under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR
    CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific
    language governing permissions and\n# limitations under the License.\n\nstatus =
    INFO\nname = HiveLog4j2\npackages = org.apache.hadoop.hive.ql.log\n\n# list of properties\nproperty.hive.log.level
    = INFO\nproperty.hive.perflogger.log.level = INFO\n\nfilters = threshold\n \nfilter.threshold.type
    = ThresholdFilter\nfilter.threshold.level = INFO\n \n# list of all appenders\nappenders
    = console\n\n# console appender\nappender.console.type = Console\nappender.console.name
    = STDOUT\nappender.console.layout.type = PatternLayout\nappender.console.layout.pattern
    = %d{ISO8601} %5p [%t] %c{2}: %m%n\n\n# list of all loggers\nloggers = DataNucleus,
    Datastore, JPOX, PerfLogger\n\nlogger.DataNucleus.name = DataNucleus\nlogger.DataNucleus.level
    = INFO\n\nlogger.Datastore.name = Datastore\nlogger.Datastore.level = INFO\n\nlogger.JPOX.name
    = JPOX\nlogger.JPOX.level = INFO\n\nlogger.PerfLogger.name = org.apache.hadoop.hive.ql.log.PerfLogger\nlogger.PerfLogger.level
    = ${sys:hive.perflogger.log.level}\n\n# root logger\nrootLogger.level = ${sys:hive.log.level}\nrootLogger.appenderRefs
    = stdout\nrootLogger.appenderRef.stdout.ref = STDOUT\n\n"
  hive-log4j2.properties.file: |
    # Licensed under the Apache License, Version 2.0 (the "License");
    # you may not use this file except in compliance with the License.
    # You may obtain a copy of the License at
    #
    #     http://www.apache.org/licenses/LICENSE-2.0
    #
    # Unless required by applicable law or agreed to in writing, software
    # distributed under the License is distributed on an "AS IS" BASIS,
    # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    # See the License for the specific language governing permissions and
    # limitations under the License.
  
    status = INFO
    name = HiveLog4j2
    packages = org.apache.hadoop.hive.ql.log
  
    # list of properties
    property.hive.log.level = INFO
    property.hive.root.logger = DRFA
    property.hive.log.dir = /tmp/
    property.hive.log.file = hive.log
    property.hive.perflogger.log.level = INFO
  
    # list of all appenders
    appenders = console, DRFA
  
    # console appender
    appender.console.type = Console
    appender.console.name = console
    appender.console.target = SYSTEM_ERR
    appender.console.layout.type = PatternLayout
    appender.console.layout.pattern = %d{ISO8601} %5p [%t] %c{2}: %m%n
  
    # daily rolling file appender
    appender.DRFA.type = RollingRandomAccessFile
    appender.DRFA.name = DRFA
    appender.DRFA.fileName = /tmp/hive.log
    # Use %pid in the filePattern to append <process-id>@<host-name> to the filename if you want separate log files for different CLI session
    appender.DRFA.filePattern = /tmp/hive.log.%d{yyyy-MM-dd}
    appender.DRFA.layout.type = PatternLayout
    appender.DRFA.layout.pattern = %d{ISO8601} %5p [%t] %c{2}: %m%n
    appender.DRFA.policies.type = Policies
    appender.DRFA.policies.time.type = TimeBasedTriggeringPolicy
    appender.DRFA.policies.time.interval = 1
    appender.DRFA.policies.time.modulate = true
    appender.DRFA.strategy.type = DefaultRolloverStrategy
    appender.DRFA.strategy.max = 30
  
    # list of all loggers
    loggers = NIOServerCnxn, ClientCnxnSocketNIO, DataNucleus, Datastore, JPOX, PerfLogger
  
    logger.NIOServerCnxn.name = org.apache.zookeeper.server.NIOServerCnxn
    logger.NIOServerCnxn.level = WARN
  
    logger.ClientCnxnSocketNIO.name = org.apache.zookeeper.ClientCnxnSocketNIO
    logger.ClientCnxnSocketNIO.level = WARN
  
    logger.DataNucleus.name = DataNucleus
    logger.DataNucleus.level = ERROR
  
    logger.Datastore.name = Datastore
    logger.Datastore.level = ERROR
  
    logger.JPOX.name = JPOX
    logger.JPOX.level = ERROR
  
    logger.PerfLogger.name = org.apache.hadoop.hive.ql.log.PerfLogger
    logger.PerfLogger.level = ${sys:hive.perflogger.log.level}
  
    # root logger
    rootLogger.level = ${sys:hive.log.level}
    rootLogger.appenderRefs = root
    rootLogger.appenderRef.root.ref = ${sys:hive.root.logger}
  hive-site.xml: "<configuration>\n\n<property>\n  <name>dfs.client.mmap.enabled</name>\n
    \ <value>false</value>\n</property>\n\n<property>\n  <name>dfs.short.circuit.shared.memory.watcher.interrupt.check.ms</name>\n
    \ <value>0</value>\n</property>\n\n<property>\n  <name>hive.auto.convert.sortmerge.join.to.mapjoin</name>\n
    \ <value>true</value>\n</property>\n\n<property>\n  <name>hive.compactor.initiator.on</name>\n
    \ <value>false</value>\n</property>\n\n<property>\n  <name>hive.compactor.worker.threads</name>\n
    \ <value>1</value>\n</property>\n\n<property>\n  <name>hive.default.fileformat.managed</name>\n
    \ <value>TextFile</value>\n</property>\n\n<property>\n  <name>hive.driver.parallel.compilation</name>\n
    \ <value>true</value>\n</property>\n\n<property>\n  <name>hive.enforce.sortmergebucketmapjoin</name>\n
    \ <value>true</value>\n</property>\n\n<property>\n  <name>hive.exec.dynamic.partition.mode</name>\n
    \ <value>nonstrict</value>\n</property>\n\n<property>\n  <name>hive.exec.max.dynamic.partitions</name>\n
    \ <value>5000</value>\n</property>\n\n<property>\n  <name>hive.exec.max.dynamic.partitions.pernode</name>\n
    \ <value>2000</value>\n</property>\n\n<property>\n  <name>hive.exec.orc.compression.strategy</name>\n
    \ <value>SPEED</value>\n</property>\n\n<property>\n  <name>hive.exec.orc.default.compress</name>\n
    \ <value>SNAPPY</value>\n</property>\n\n<property>\n  <name>hive.exec.orc.default.stripe.size</name>\n
    \ <value>67108864</value>\n</property>\n\n<property>\n  <name>hive.exec.orc.encoding.strategy</name>\n
    \ <value>SPEED</value>\n</property>\n\n<property>\n  <name>hive.exec.orc.split.strategy</name>\n
    \ <value>HYBRID</value>\n</property>\n\n<property>\n  <name>hive.exec.reducers.bytes.per.reducer</name>\n
    \ <value>67108864</value>\n</property>\n\n<property>\n  <name>hive.exec.reducers.max</name>\n
    \ <value>1009</value>\n</property>\n\n<property>\n  <name>hive.limit.optimize.enable</name>\n
    \ <value>true</value>\n</property>\n\n<property>\n  <name>hive.limit.pushdown.memory.usage</name>\n
    \ <value>0.04</value>\n</property>\n\n<property>\n  <name>hive.map.aggr.hash.min.reduction</name>\n
    \ <value>0.99</value>\n</property>\n\n<property>\n  <name>hive.mapjoin.bucket.cache.size</name>\n
    \ <value>10000</value>\n</property>\n\n<property>\n  <name>hive.mapjoin.hybridgrace.hashtable</name>\n
    \ <value>false</value>\n</property>\n\n<property>\n  <name>hive.merge.nway.joins</name>\n
    \ <value>true</value>\n  <description>\n    Set it to false if necessary. Cf. HIVE-21189\n
    \ </description>\n</property>\n\n<property>\n  <name>hive.metastore.cache.pinobjtypes</name>\n
    \ <value>Table,Database,Type,FieldSchema,Order</value>\n</property>\n\n<property>\n
    \ <name>hive.metastore.client.connect.retry.delay</name>\n  <value>5s</value>\n</property>\n\n<property>\n
    \ <name>hive.metastore.connect.retries</name>\n  <value>24</value>\n</property>\n\n<property>\n
    \ <name>hive.metastore.event.listeners</name>\n  <value>org.apache.hive.hcatalog.listener.DbNotificationListener</value>\n</property>\n\n<property>\n
    \ <name>hive.metastore.failure.retries</name>\n  <value>24</value>\n</property>\n\n<!--\n
    \ see HiveServer2.startPrivilegeSynchronizer() to learn when HiveServer2 creates
    ZooKeeperClient\n -->\n<property>\n  <name>hive.metastore.pre.event.listeners</name>\n
    \ <value></value>\n</property>\n<property>\n  <name>metastore.pre.event.listeners</name>\n
    \ <value></value>\n</property>\n\n<property>\n  <name>hive.metastore.server.max.threads</name>\n
    \ <value>100000</value>\n</property>\n\n<property>\n  <name>metastore.stats.fetch.bitvector</name>\n
    \ <value>true</value>\n</property>\n\n<property>\n  <name>hive.optimize.bucketmapjoin</name>\n
    \ <value>true</value>\n</property>\n\n<property>\n  <name>hive.optimize.bucketmapjoin.sortedmerge</name>\n
    \ <value>true</value>\n</property>\n\n<property>\n  <name>hive.optimize.index.filter</name>\n
    \ <value>true</value>\n</property>\n\n<property>\n  <name>hive.optimize.metadataonly</name>\n
    \ <value>true</value>\n</property>\n\n<property>\n  <name>hive.server2.max.start.attempts</name>\n
    \ <value>5</value>\n</property>\n\n<property>\n  <name>hive.server2.transport.mode</name>\n
    \ <value>all</value>\n</property>\n\n<property>\n  <name>hive.server2.keystore.path</name>\n
    \ <value>/opt/mr3-run/key/hivemr3-ssl-certificate.jks</value>\n</property>\n\n<property>\n
    \ <name>hive.server2.keystore.password</name>\n  <value>_</value>\n</property>\n\n<property>\n
    \ <name>hive.metastore.use.SSL</name>\n  <value>false</value>\n</property>\n\n<property>\n
    \ <name>hive.metastore.keystore.path</name>\n  <value>/opt/mr3-run/key/hivemr3-ssl-certificate.jks</value>\n</property>\n\n<property>\n
    \ <name>hive.metastore.truststore.path</name>\n  <value>/opt/mr3-run/key/hivemr3-ssl-certificate.jks</value>\n</property>\n\n<property>\n
    \ <name>hive.server2.webui.port</name>\n  <value>0</value>\n</property>\n\n<property>\n
    \ <name>hive.stats.autogather</name>\n  <value>true</value>\n  <description>\n    By
    default, Hive collects stats when running operations like alter table partition
    and create table.\n    However, collecting stats requires Metastore to list all
    files under the table directory, which can be expensive on S3.\n    Cf. HIVE-20246
    and tblproperties('DO_NOT_UPDATE_STATS'='TRUE')\n  </description>\n</property>\n\n<property>\n
    \ <name>hive.stats.fetch.column.stats</name>\n  <value>true</value>\n</property>\n\n<property>\n
    \ <name>hive.support.concurrency</name>\n  <value>true</value>\n</property>\n\n<property>\n
    \ <name>hive.tez.auto.reducer.parallelism</name>\n  <value>true</value>\n</property>\n\n<property>\n
    \ <name>hive.tez.bucket.pruning</name>\n  <value>true</value>\n</property>\n\n<property>\n
    \ <name>hive.txn.manager</name>\n  <value>org.apache.hadoop.hive.ql.lockmgr.DbTxnManager</value>\n</property>\n\n<property>\n
    \ <name>hive.user.install.directory</name>\n  <value>/user/</value>\n</property>\n\n<property>\n
    \ <name>hive.vectorized.execution.mapjoin.minmax.enabled</name>\n  <value>true</value>\n</property>\n\n<property>\n
    \ <name>hive.vectorized.execution.mapjoin.native.fast.hashtable.enabled</name>\n
    \ <value>true</value>\n</property>\n\n<property>\n  <name>hive.vectorized.groupby.checkinterval</name>\n
    \ <value>4096</value>\n</property>\n\n<property>\n  <name>hive.vectorized.adaptor.usage.mode</name>\n
    \ <value>all</value>\n  <description>\n    Set to chosen for stability or to avoid
    vectorizing UDFs that do not have native vectorized versions available. Cf. HIVE-21935\n
    \ </description>\n</property>\n\n<!-- Security -->\n\n<property>\n  <name>hive.security.authorization.enabled</name>\n
    \ <value>true</value>\n</property>\n\n<property>\n  <name>hive.security.authenticator.manager</name>\n
    \ <!-- <value>org.apache.hadoop.hive.ql.security.HadoopDefaultAuthenticator</value>
    -->\n  <!-- <value>org.apache.hadoop.hive.ql.security.ProxyUserAuthenticator</value>
    -->\n  <value>org.apache.hadoop.hive.ql.security.HadoopDefaultAuthenticator</value>\n</property>\n\n<property>\n
    \ <name>hive.security.authorization.manager</name>\n  <!-- <value>org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdConfOnlyAuthorizerFactory</value>
    -->\n  <!-- <value>org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactory</value>
    -->\n  <value>org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdConfOnlyAuthorizerFactory</value>\n</property>\n\n<!--
    set to false in order not to create ZooKeeperClient in HiveServer2\n  With Ranger:\n
    \   RangerHiveAuthorizerBase.getHivePolicyProvider() returns RangerHivePolicyProvider.\n
    \   Hence we should explicitly set hive.privilege.synchronizer to false.\n -->\n<property>\n
    \ <name>hive.privilege.synchronizer</name>\n  <value>false</value>\n</property>\n\n<property>\n
    \ <name>hive.security.metastore.authenticator.manager</name>\n  <value>org.apache.hadoop.hive.ql.security.HadoopDefaultMetastoreAuthenticator</value>\n</property>\n\n<property>\n
    \ <name>hive.security.metastore.authorization.auth.reads</name>\n  <value>true</value>\n</property>\n\n<property>\n
    \ <name>hive.security.metastore.authorization.manager</name>\n  <value>org.apache.hadoop.hive.ql.security.authorization.DefaultHiveMetastoreAuthorizationProvider</value>\n
    \ <!-- if enabled, a ZooKeeper client starts, so hive.zookeeper.quorum should be
    set properly -->\n  <!-- <value>org.apache.hadoop.hive.ql.security.authorization.StorageBasedAuthorizationProvider</value>
    -->\n</property>\n\n<property>\n  <name>hive.server2.enable.doAs</name>\n  <value>false</value>\n</property>\n\n<property>
    \n  <name>hive.security.authorization.sqlstd.confwhitelist.append</name>\n  <value>hive\\.querylog\\.location.*|hive\\.mr3\\.map\\.task.*|hive\\.mr3\\.reduce\\.task.*</value>\n</property>\n\n<!--
    Metastore -->\n\n<property>\n  <name>hive.metastore.db.type</name>\n  <value>MYSQL</value>\n</property>\n\n<!--
    set to com.mysql.jdbc.Driver if necessary -->\n<property>\n  <name>javax.jdo.option.ConnectionDriverName</name>\n
    \ <value>com.mysql.cj.jdbc.Driver</value>\n</property>\n\n<property>\n  <name>javax.jdo.option.ConnectionURL</name>\n
    \ <value>jdbc:mysql://${hive.database.host}/${hive.database.name}?createDatabaseIfNotExist=true&amp;useSSL=false</value>\n
    \ <!-- <value>jdbc:mysql://${hive.database.host}/${hive.database.name}?createDatabaseIfNotExist=true&amp;useSSL=true&amp;verifyServerCertificate=true</value>
    -->\n</property>\n\n<property>\n  <name>javax.jdo.option.ConnectionUserName</name>\n
    \ <value>root</value>\n</property>\n\n<property>\n  <name>javax.jdo.option.ConnectionPassword</name>\n
    \ <value>passwd</value>\n</property>\n\n<property>\n  <name>hive.metastore.kerberos.keytab.file</name>\n
    \ <value>${hive.metastore.keytab.file}</value>\n</property>\n\n<property>\n  <name>hive.metastore.kerberos.principal</name>\n
    \ <value>${hive.metastore.principal}</value>\n</property>\n\n<property>\n  <name>hive.metastore.sasl.enabled</name>\n
    \ <value>${hive.metastore.secure.mode}</value>\n</property>\n\n<property>\n  <name>hive.metastore.uris</name>\n
    \ <value>thrift://${hive.metastore.host}:${hive.metastore.port}</value>\n</property>\n\n<property>\n
    \ <name>hive.metastore.warehouse.dir</name>\n  <value>${hive.warehouse.dir}</value>\n</property>\n\n<property>\n
    \ <name>hive.metastore.event.db.notification.api.auth</name>\n  <value>false</value>\n</property>\n\n<property>\n
    \ <name>metastore.metastore.event.db.notification.api.auth</name>\n  <value>false</value>\n</property>\n\n<!--
    HiveServer2 -->\n\n<property>\n  <name>hive.users.in.admin.role</name>\n  <value>root,hive</value>\n</property>\n\n<property>\n
    \ <name>hive.server2.authentication</name>\n  <value>${hive.server2.authentication.mode}</value>\n</property>\n\n<property>\n
    \ <name>hive.server2.authentication.kerberos.keytab</name>\n  <value>${hive.server2.keytab.file}</value>\n</property>\n\n<property>\n
    \ <name>hive.server2.authentication.kerberos.principal</name>\n  <value>${hive.server2.principal}</value>\n</property>\n\n<property>\n
    \ <name>hive.server2.thrift.http.port</name>\n  <value>${hive.server2.http.port}</value>\n</property>\n\n<property>\n
    \ <name>hive.server2.thrift.bind.host</name>\n  <value>${hive.server2.host}</value>\n</property>\n\n<property>\n
    \ <name>hive.server2.thrift.port</name>\n  <value>${hive.server2.port}</value>\n</property>\n\n<property>\n
    \ <name>hive.server2.use.SSL</name>\n  <value>false</value>\n</property>\n\n<property>\n
    \ <name>hive.server2.thrift.sasl.qop</name>\n  <value>auth-conf</value>\n</property>\n\n<!--
    Hive (configurable) -->\n\n<property>\n  <name>hive.auto.convert.join.noconditionaltask.size</name>\n
    \ <value>4000000000</value>\n</property>\n    \n<property>\n  <name>hive.optimize.dynamic.partition.hashjoin</name>\n
    \ <value>true</value>\n</property>\n\n<property>\n  <name>metastore.aggregate.stats.cache.enabled</name>\n
    \ <value>true</value>\n</property>\n\n<property>\n  <name>hive.metastore.aggregate.stats.cache.enabled</name>\n
    \ <value>true</value>\n</property>\n\n<property>\n  <name>hive.query.reexecution.stats.persist.scope</name>\n
    \ <value>query</value>\n</property>\n\n<property>\n  <name>hive.query.results.cache.enabled</name>\n
    \ <value>true</value>\n</property>\n\n<property>\n  <name>hive.server2.idle.operation.timeout</name>\n
    \ <value>4h</value>\n</property>\n\n<property>\n  <name>hive.server2.idle.session.timeout</name>\n
    \ <value>4h</value>\n</property>\n\n<!-- MR3 LLAP (configurable) -->\n\n<property>\n
    \ <name>hive.llap.io.enabled</name>\n  <value>false</value>\n</property>\n\n<property>\n
    \ <name>hive.llap.io.allocator.mmap</name>\n  <value>false</value>\n</property>\n\n<!--
    use /ephemeral1/llapio on AWS EKS -->\n<property>\n  <name>hive.llap.io.allocator.mmap.path</name>\n
    \ <value>/data1/llap</value>\n</property>\n\n<property>\n  <name>hive.llap.io.memory.size</name>\n
    \ <value>72Gb</value>\n</property>\n\n<property>\n  <name>hive.mr3.llap.headroom.mb</name>\n
    \ <value>8192</value>\n</property>\n\n<property>\n  <name>hive.llap.io.threadpool.size</name>\n
    \ <value>10</value>\n  <description> \n    hive.llap.io.threadpool.size must be
    >= # of TaskAttempts running in a ContainerWorker (and hive.llap.daemon.num.executors).\n
    \   Cf. HIVE-24626\n  </description>\n</property>\n    \n<property>\n  <name>hive.llap.daemon.num.executors</name>\n
    \ <value>10</value>\n  <description> \n    Used as an estimate number of Reducers
    in LlapDecider when no ContainerWorkers are running\n  </description>\n</property>\n\n<!--
    MR3 LLAP (fixed) -->\n\n<property>\n  <name>hive.execution.engine</name>\n  <value>tez</value>\n</property>\n\n<property>\n
    \ <name>hive.execution.mode</name>\n  <value>llap</value>\n</property>\n\n<property>\n
    \ <name>hive.mr3.container.use.per.query.cache</name>\n  <value>true</value>\n</property>\n\n<property>\n
    \ <name>hive.llap.hs2.coordinator.enabled</name>\n  <value>false</value>\n</property>\n\n<property>\n
    \ <name>hive.llap.daemon.service.hosts</name>\n  <value></value>\n</property>\n\n<property>\n
    \ <name>hive.strict.checks.cartesian.product</name>\n  <value>false</value>\n</property>\n\n<property>\n
    \ <name>hive.server2.support.dynamic.service.discovery</name>\n  <value>false</value>\n</property>\n\n<property>\n
    \ <name>hive.llap.execution.mode</name>\n  <value>all</value>\n</property>\n    \n<property>\n
    \ <name>hive.aux.jars.path</name>\n  <value></value>\n</property>\n\n<!-- set to
    false when not using HDFS -->\n<property>\n  <name>hive.resource.use.hdfs.location</name>\n
    \ <value>false</value>\n  <description>\n    Can be set to false if no additional
    resources are added (other than hive.aux.jars.path)\n  </description>\n</property>\n
    \   \n<!-- MR3 -->\n\n<property>\n  <name>hive.mr3.exec.print.summary</name>\n  <value>true</value>\n</property>\n\n<!--
    to use individual session mode, do not pass MR3_APPLICATION_ID_TIMESTAMP to HiveServer2
    -->\n<property>\n  <name>hive.server2.mr3.share.session</name>\n  <value>true</value>\n</property>\n\n<property>\n
    \ <name>hive.mr3.container.combine.taskattempts</name>\n  <value>true</value>\n</property>\n\n<property>\n
    \ <name>hive.mr3.container.reuse</name>\n  <value>true</value>\n</property>\n\n<property>\n
    \ <name>hive.mr3.containergroup.scheme</name>\n  <value>all-in-one</value>\n</property>\n\n<property>\n
    \ <name>hive.mr3.container.max.java.heap.fraction</name>\n  <value>0.7f</value>\n</property>\n\n<property>\n
    \ <name>hive.mr3.resource.vcores.divisor</name>\n  <value>1</value>\n</property>\n\n<property>\n
    \ <name>hive.mr3.map.task.memory.mb</name>\n  <value>1000</value>\n</property>\n\n<property>\n
    \ <name>hive.mr3.map.task.vcores</name>\n  <value>1</value>\n</property>\n\n<property>\n
    \ <name>hive.mr3.reduce.task.memory.mb</name>\n  <value>1000</value>\n</property>\n\n<property>\n
    \ <name>hive.mr3.reduce.task.vcores</name>\n  <value>1</value>\n</property>\n\n<property>\n
    \ <name>hive.mr3.all-in-one.containergroup.memory.mb</name>\n  <value>2000</value>\n</property>\n\n<property>\n
    \ <name>hive.mr3.all-in-one.containergroup.vcores</name>\n  <value>1</value>\n</property>\n\n<property>\n
    \ <name>hive.mr3.use.daemon.shufflehandler</name>\n  <value>1</value>\n  <description>\n
    \   Adjust tez.shuffle.max.threads in tez-site.xml (to a non-zero value) if necessary\n
    \ </description>\n</property>\n\n<property>\n  <name>hive.mr3.am.task.max.failed.attempts</name>\n
    \ <value>2</value>\n</property>\n\n<property>\n  <name>hive.mr3.delete.vertex.local.directory</name>\n
    \ <value>false</value>\n</property>\n\n<property>\n  <name>hive.mr3.bucket.mapjoin.estimate.num.nodes</name>\n
    \ <value>-1</value>\n  <description>\n    Set to -1 in order to ask MR3 to get the
    number of Nodes at runtime\n  </description>\n</property>\n\n<!-- scheduling 0.10
    -->\n\n<property>\n  <name>hive.tez.llap.min.reducer.per.executor</name>\n  <value>0.2f</value>\n</property>\n\n<!--
    speculative execution 1.1 -->\n\n<property>\n  <name>hive.mr3.am.task.concurrent.run.threshold.percent</name>\n
    \ <value>99</value>\n</property>\n\n<!-- capacity scheduling when mr3.dag.queue.scheme
    is set to capacity -->\n\n<property>\n  <name>hive.mr3.dag.queue.name</name>\n  <value>default</value>\n</property>\n\n<property>\n
    \ <name>hive.mr3.dag.queue.capacity.specs</name>\n  <value>default:0</value>\n</property>\n\n<!--
    Kubernetes -->\n\n<property>\n  <name>hive.mr3.localize.session.jars</name>\n  <value>false</value>\n</property>\n\n<!--\n
    \ If the user chooses to override hive.exec.stagingdir for running such queries
    as 'analyze table',\n  it should be set to a directory (with write permission) in
    the same file system where target tables reside.\n  For example, if target tables
    reside on S3, hive.exec.stagingdir should point to a directory on S3.\n -->\n\n<!--\n
    \ It is okay to use /opt/mr3-run/scratch-dir for hive.exec.scratchdir and hive.downloaded.resources.dir.\n
    -->\n<property>\n  <name>hive.exec.scratchdir</name>\n  <value>s3a://blox-dev-use1-internal/hivemr3/workdir</value>\n</property>\n\n<property>\n
    \ <name>hive.query.results.cache.directory</name>\n  <value>s3a://blox-dev-use1-internal/hivemr3/workdir/_resultscache_</value>\n</property>\n\n<property>\n
    \ <name>hive.downloaded.resources.dir</name>\n  <value>/opt/mr3-run/work-dir/${hive.session.id}_resources</value>\n</property>\n\n<property>\n
    \ <name>hive.exec.local.scratchdir</name>\n  <value>/opt/mr3-run/scratch-dir</value>\n</property>\n\n<property>\n
    \ <name>hive.server2.logging.operation.log.location</name>\n  <value>/opt/mr3-run/scratch-dir/operation_logs</value>\n</property>\n\n<property>\n
    \ <name>hive.mr3.dag.additional.credentials.source</name>\n  <value></value>\n</property>\n\n<!--
    Token renewal -->\n\n<property>\n  <name>hive.cluster.delegation.token.renew-interval</name>\n
    \ <value>1</value>\n  <description>\n    The unit is days, not milli-seconds.\n
    \ </description>\n</property>\n\n<!-- Compaction -->\n\n<property>\n  <name>hive.mr3.compaction.using.mr3</name>\n
    \ <value>true</value>\n</property>\n\n<!-- Repl -->\n\n<property>\n  <name>hive.distcp.privileged.doAs</name>\n
    \ <value>hive</value>\n</property>\n\n<property>\n  <name>hive.repl.rootdir</name>\n
    \ <value>/opt/mr3-run/work-dir</value>\n</property>\n\n<!-- Clean JobConf to be
    passed to Tez -->\n\n<property>\n  <name>hive.mr3.config.remove.keys</name>\n  <value>hive.txn.valid.txns,hive.query.string</value>\n</property>\n\n<!--\n
    \ ipc.*: do not remove (e.g., ipc.maximum.data.length)\n  mapreduce.job.*: used
    by MapReduce interfaces\n  mapreduce.workflow.*, mapreduce.client.*: not worth removing\n
    \ Cf. dfs.balancer.*, dfs.federation.*, dfs.ha*, dfs.qjournal*, dfs.webhdfs*, hadoop.*,
    mapreduce.application.*, mapreduce.map.*, mapreduce.reduce.*, mapreduce.task.*\n
    \ -->\n<property>\n  <name>hive.mr3.config.remove.prefixes</name>\n  <value>atlas.hook.,datanucleus.,ftp.,ha.,javax.,mapreduce.jobhistory.,metastore.,hive.metastore.,nfs.,yarn.</value>\n</property>\n\n<!--
    Hive 4 -->\n\n<property>\n  <name>hive.metastore.runworker.in</name>\n  <value>metastore</value>\n</property>\n\n<property>\n
    \ <name>hive.metastore.warehouse.external.dir</name>\n  <value>${hive.warehouse.dir}</value>\n</property>\n\n<property>\n
    \ <name>hive.acid.direct.insert.enabled</name>\n  <value>true</value>\n</property>\n\n<property>\n
    \ <name>hive.optimize.scan.probedecode</name>\n  <value>true</value>\n</property>\n\n<property>\n
    \ <name>hive.zookeeper.killquery.enable</name>\n  <value>false</value>\n</property>\n\n<property>\n
    \ <name>hive.llap.io.proactive.eviction.enabled</name>\n  <value>false</value>\n</property>\n\n<!--
    S3 -->\n\n<property>\n  <name>hive.llap.io.use.fileid.path</name>\n  <value>false</value>\n
    \ <description>\n    In practice, we have hive.llap.io.use.fileid.path = \"is HDFS\".\n
    \   Cf. HIVE-20338 (LLAP: Force synthetic file-id for filesystems which have HDFS
    protocol impls with POSIX mutation semantics)\n  </description>\n</property>\n\n<!--
    can be set for performance tuning when using S3 -->\n\n<!-- S3 input listing (Cf.
    mapreduce.input.fileinputformat.list-status.num-threads) -->\n<property>\n  <name>hive.exec.input.listing.max.threads</name>\n
    \ <value>50</value>\n</property>\n\n<!-- MSCK (Metastore Check) on S3 -->\n<property>\n
    \ <name>hive.metastore.fshandler.threads</name>\n  <value>30</value>\n</property>\n<property>\n
    \ <name>hive.msck.repair.batch.size</name>\n  <value>3000</value>\n</property>\n\n<!--
    dynamic partition query on S3 -->\n<property>\n  <name>hive.load.dynamic.partitions.thread</name>\n
    \ <value>25</value>\n</property>\n\n<!-- with HIVE-21390, for hive.exec.orc.split.strategy=BI
    -->\n<property>\n  <name>hive.exec.orc.blob.storage.split.size</name>\n  <value>134217728</value>\n</property>\n\n<!--
    for hive.exec.orc.split.strategy=ETL -->\n<property>\n  <name>hive.orc.compute.splits.num.threads</name>\n
    \ <value>20</value>\n</property>\n\n<property>\n  <name>hive.orc.splits.include.file.footer</name>\n
    \ <value>false</value>\n</property>\n\n<!-- Correctness -->\n\n<property>\n  <name>hive.optimize.shared.work</name>\n
    \ <value>true</value>\n</property>\n\n<property>\n  <name>hive.optimize.shared.work.extended</name>\n
    \ <value>true</value>\n</property>\n\n<property>\n  <name>hive.optimize.shared.work.semijoin</name>\n
    \ <value>true</value>\n</property>\n\n<!-- Correctness, Hive 4 -->\n\n<property>\n
    \ <name>hive.optimize.shared.work.dppunion</name>\n  <value>false</value>\n</property>\n\n<property>\n
    \ <name>hive.optimize.shared.work.dppunion.merge.eventops</name>\n  <value>false</value>\n</property>\n\n<property>\n
    \ <name>hive.optimize.shared.work.downstream.merge</name>\n  <value>false</value>\n</property>\n\n<property>\n
    \ <name>hive.optimize.shared.work.parallel.edge.support</name>\n  <value>false</value>\n</property>\n\n<property>\n
    \ <name>hive.optimize.shared.work.merge.ts.schema</name>\n  <value>false</value>\n</property>\n\n<property>\n
    \ <name>hive.optimize.cte.materialize.threshold</name>\n  <value>-1</value>\n</property>\n\n<property>\n
    \ <name>hive.tez.bloom.filter.merge.threads</name>\n  <value>0</value>\n</property>\n\n<property>\n
    \ <name>hive.auto.convert.anti.join</name>\n  <value>false</value>\n</property>\n\n<!--
    Iceberg -->\n\n<property>\n  <name>iceberg.catalog</name>\n  <value>iceberg</value>\n</property>\n\n<property>\n
    \ <name>iceberg.catalog.iceberg.type</name>\n  <value>hive</value>\n</property>\n\n<property>\n
    \ <name>iceberg.catalog.iceberg.clients</name>\n  <value>10</value>\n</property>\n\n<property>\n
    \ <name>iceberg.catalog.iceberg.uri</name>\n  <value>thrift://${hive.metastore.host}:${hive.metastore.port}</value>\n</property>\n\n<property>\n
    \ <name>iceberg.catalog.iceberg.warehouse</name>\n  <value>${hive.warehouse.dir}</value>\n</property>\n\n<property>\n
    \ <name>iceberg.mr.split.size</name>\n  <value>16777216</value>\n</property>\n\n<property>\n
    \ <name>write.format.default</name>\n  <value>orc</value>\n</property>\n\n</configuration>\n"
  hplsql-site.xml: |
    <configuration>
      <property>
        <name>hplsql.conn.default</name>
        <value>hive2conn</value>
      </property>
  
      <property>
        <name>hplsql.conn.hive2conn</name>
        <value>org.apache.hive.jdbc.HiveDriver;jdbc:hive2://localhost:9852;hive;hive</value>
      </property>
    </configuration>
  jgss.conf: |
    com.sun.security.jgss.initiate {
       com.sun.security.auth.module.Krb5LoginModule required
       doNotPrompt=true
       useTicketCache=false
       useKeyTab=true
       debug=true;
    };
  krb5.conf: |
    [libdefaults]
      dns_lookup_realm = false
      ticket_lifetime = 24h
    # renew_lifetime = 7d
      forwardable = true
      rdns = false
      default_realm = RED
      default_ccache_name = /tmp/krb5cc_%{uid}
  
    [realms]
      RED = {
        admin_server = red0
        kdc = red0
      }
  mapred-site.xml: |+
    <configuration>
    </configuration>
  
  mr3-site.xml: "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<?xml-stylesheet type=\"text/xsl\"
    href=\"configuration.xsl\"?>\n<configuration>\n\n<property>\n  <name>mr3.runtime</name>\n
    \ <value>tez</value>\n</property>\n\n<property>\n  <name>mr3.cluster.use.hadoop-libs</name>\n
    \ <value>false</value>\n</property>\n\n<property>\n  <name>mr3.lib.uris</name>\n
    \ <value></value>\n</property>\n\n<property>\n  <name>mr3.aux.uris</name>\n  <value></value>\n</property>\n\n<!--
    add for LocalProcess with Kerberos\n     -Djava.security.krb5.conf=/opt/mr3-run/conf/krb5.conf
    -->\n<!-- additional options:\n     -Djavax.security.auth.useSubjectCredsOnly=false\n
    \    -Djava.security.auth.login.config=/opt/mr3-run/conf/jgss.conf\n     -Dsun.security.jgss.debug=true
    -->\n<!-- add-opens java.base/java.lang=ALL-UNNAMED is added by run-master.sh -->\n<property>\n
    \ <name>mr3.am.launch.cmd-opts</name>\n  <value>-XX:+AlwaysPreTouch -Xss512k -XX:+UseG1GC
    -XX:+ResizeTLAB -XX:+UseNUMA -XX:InitiatingHeapOccupancyPercent=40 -XX:G1ReservePercent=20
    -XX:MaxGCPauseMillis=200 -XX:MetaspaceSize=1024m -server -Djava.net.preferIPv4Stack=true
    -XX:NewRatio=8 -Dhadoop.metrics.log.level=WARN -Dlog4j.configurationFile=k8s-mr3-container-log4j2.properties
    -Djavax.net.ssl.trustStore=/opt/mr3-run/key/hivemr3-ssl-certificate.jks -Djavax.net.ssl.trustStoreType=jks</value>\n</property>\n\n<property>\n
    \ <name>mr3.am.staging-dir</name>\n  <value></value>\n</property>\n\n<property>\n
    \ <name>mr3.am.generate.dag.graph.viz</name>\n  <value>false</value>\n</property>\n\n<property>\n
    \ <name>mr3.container.kill.policy</name>\n  <value>container.kill.wait.workervertex</value>\n
    \ <description>\n    container.kill.wait.workervertex: wait until WorkerVertexes
    terminate\n    container.kill.nowait: kill without waiting \n  </description>\n</property>\n\n<property>\n
    \ <name>mr3.am.max.num.concurrent.dags</name>\n  <value>32</value>\n</property>\n\n<property>\n
    \ <name>mr3.dag.queue.scheme</name>\n  <value>common</value>\n</property>\n\n<property>\n
    \ <name>mr3.dag.priority.scheme</name>\n  <value>fifo</value>\n</property>\n\n<property>\n
    \ <name>mr3.vertex.priority.scheme</name>\n  <value>intact</value>\n</property>\n\n<property>\n
    \ <name>mr3.am.task.max.failed.attempts</name>\n  <value>3</value>\n</property>\n\n<property>\n
    \ <name>mr3.am.task.retry.on.fatal.error</name>\n  <value>true</value>\n</property>\n\n<property>\n
    \ <name>mr3.am.task.no.retry.errors</name>\n  <value>MapJoinMemoryExhaustionError,OutOfMemoryError</value>\n</property>\n\n<property>\n
    \ <name>mr3.am.client.thread-count</name>\n  <value>32</value>\n</property>\n\n<property>\n
    \ <name>mr3.async.logging</name>\n  <value>true</value>\n</property>\n\n<property>\n
    \ <name>mr3.am.permit.custom.user.class</name>\n  <value>true</value>\n</property>\n\n<!--
    resource scheduler -->\n\n<property>\n  <name>mr3.am.resourcescheduler.max.requests.per.taskscheduler</name>\n
    \ <value>1000</value>\n</property>\n\n<!-- container -->\n\n<!-- add-opens java.base/java.lang=ALL-UNNAMED
    is added by run-master.sh -->\n<property>\n  <name>mr3.container.launch.cmd-opts</name>\n
    \ <value>-XX:+AlwaysPreTouch -Xss512k -XX:+UseG1GC -XX:+ResizeTLAB -XX:+UseNUMA
    -XX:InitiatingHeapOccupancyPercent=40 -XX:G1ReservePercent=20 -XX:MaxGCPauseMillis=200
    -XX:MetaspaceSize=1024m -server -Djava.net.preferIPv4Stack=true -XX:NewRatio=8 -Dlog4j.configurationFile=k8s-mr3-container-log4j2.properties
    -Djavax.net.ssl.trustStore=/opt/mr3-run/key/hivemr3-ssl-certificate.jks -Djavax.net.ssl.trustStoreType=jks</value>\n</property>\n\n<property>\n
    \ <name>mr3.container.reuse</name>\n  <value>true</value>\n</property>\n\n<property>\n
    \ <name>mr3.container.stop.cross.dag.reuse</name>\n  <value>false</value>\n</property>\n\n<property>\n
    \ <name>mr3.container.idle.timeout.ms</name>\n  <value>3600000</value>\n</property>\n\n<property>\n
    \ <name>mr3.heartbeat.task.timeout.ms</name>\n  <value>120000</value>\n</property>\n\n<property>\n
    \ <name>mr3.heartbeat.container.timeout.ms</name>\n  <value>300000</value>\n</property>\n\n<property>\n
    \ <name>mr3.am.node-blacklisting.enabled</name>\n  <value>false</value>\n</property>\n\n<property>\n
    \ <name>mr3.am.maxtaskfailure.percent</name>\n  <value>1</value>\n</property>\n\n<property>\n
    \ <name>mr3.container.termination.checker.timeout.ms</name>\n  <value>300000</value>\n</property>\n\n<!--
    Kubernetes -->\n\n<!-- mr3.master.mode is set in mr3-setup.sh --> \n\n<property>\n
    \ <name>mr3.am.acls.enabled</name>\n  <value>false</value>\n</property>\n\n<property>\n
    \ <name>mr3.am.resource.memory.mb</name>\n  <value>1000</value>\n</property>\n\n<property>\n
    \ <name>mr3.am.resource.cpu.cores</name>\n  <value>1</value>\n</property>\n\n<property>\n
    \ <name>mr3.am.local.resourcescheduler.max.memory.mb</name>\n  <value>500</value>\n</property>\n\n<property>\n
    \ <name>mr3.am.local.resourcescheduler.max.cpu.cores</name>\n  <value>1</value>\n</property>\n\n<property>\n
    \ <name>mr3.am.worker.mode</name>\n  <value>kubernetes</value>\n</property>\n\n<property>\n
    \ <name>mr3.container.resourcescheduler.type</name>\n  <value>kubernetes</value>\n</property>\n\n<!--
    AWS_REGION for running on AWS EKS -->\n<property>\n  <name>mr3.am.launch.env</name>\n
    \ <value>LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/mr3-run/hadoop/apache-hadoop/lib/native,HADOOP_CREDSTORE_PASSWORD,AWS_ACCESS_KEY_ID,AWS_SECRET_ACCESS_KEY,AWS_REGION,USE_JAVA_17</value>\n</property>\n\n<!--
    $LD_LIBRARY_PATH is automatically expanded to the current value inside DAGAppMaster
    (from mr3.am.launch.env), so do not include it -->\n<!-- AWS_REGION for running
    on AWS EKS -->\n<property>\n  <name>mr3.container.launch.env</name>\n  <value>LD_LIBRARY_PATH=/opt/mr3-run/hadoop/apache-hadoop/lib/native,HADOOP_CREDSTORE_PASSWORD,AWS_ACCESS_KEY_ID,AWS_SECRET_ACCESS_KEY,AWS_REGION,USE_JAVA_17</value>\n</property>\n\n<property>\n
    \ <name>mr3.am.delete.local.working-dir</name>\n  <value>false</value>\n</property>\n\n<property>\n
    \ <name>mr3.am.local.working-dir</name>\n  <value>/opt/mr3-run/am-local-dir/am-local-working-dir</value>\n</property>\n\n<property>\n
    \ <name>mr3.am.local.log-dir</name>\n  <value>/opt/mr3-run/am-local-dir/am-local-log-dir</value>\n</property>\n\n<!--
    These variables are all set in mr3/mr3-setup.sh:\n  mr3.cluster.additional.classpath
    \n  mr3.principal\n  mr3.keytab\n  mr3.token.renewal.hdfs.enabled\n  mr3.token.renewal.hive.enabled\n
    -->\n\n<property>\n  <name>mr3.token.renewal.pass.credentials.via.memory</name>\n
    \ <value>true</value>\n</property>\n\n<property>\n  <name>mr3.am.token.renewal.paths</name>\n
    \ <value></value>\n</property>\n\n<!-- These variables are all set in mr3/mr3-setup.sh
    (for Kubernetes):\n  mr3.k8s.namespace\n  mr3.k8s.pod.master.serviceaccount\n  mr3.k8s.pod.worker.serviceaccount\n
    \ mr3.k8s.pod.master.image\n  mr3.k8s.pod.master.user\n  mr3.k8s.master.working.dir\n
    \ mr3.k8s.master.persistentvolumeclaim.mounts\n  mr3.k8s.pod.worker.image\n  mr3.k8s.pod.worker.user\n
    \ mr3.k8s.worker.working.dir\n  mr3.k8s.java.io.tmpdir\n  mr3.k8s.worker.persistentvolumeclaim.mounts\n
    \ mr3.k8s.conf.dir.configmap\n  mr3.k8s.conf.dir.mount.dir\n  mr3.k8s.keytab.secret\n
    \ mr3.k8s.worker.secret\n  mr3.k8s.mount.keytab.secret\n  mr3.k8s.mount.worker.secret\n
    \ mr3.k8s.keytab.mount.dir\n  mr3.k8s.keytab.mount.file\n -->\n\n<property>\n  <name>mr3.k8s.master.command</name>\n
    \ <value>/opt/mr3-run/hive/run-master.sh</value>\n</property>\n\n<property>\n  <name>mr3.k8s.worker.command</name>\n
    \ <value>/opt/mr3-run/hive/run-worker.sh</value>\n</property>\n\n<property>\n  <name>mr3.k8s.worker.total.max.memory.gb</name>\n
    \ <value>1048576</value>\n</property>\n\n<property>\n  <name>mr3.k8s.worker.total.max.cpu.cores</name>\n
    \ <value>1048576</value>\n</property>\n\n<property>\n  <name>mr3.k8s.pod.cpu.cores.max.multiplier</name>\n
    \ <value>1.0d</value>\n</property>\n\n<property>\n  <name>mr3.k8s.pod.memory.max.multiplier</name>\n
    \ <value>1.0d</value>\n</property>\n\n<property>\n  <name>mr3.k8s.api.server.url</name>\n
    \ <value>https://kubernetes.default.svc</value>\n</property>\n\n<property>\n  <name>mr3.k8s.nodes.polling.interval.ms</name>\n
    \ <value>60000</value>\n</property>\n\n<property>\n  <name>mr3.k8s.pods.polling.interval.ms</name>\n
    \ <value>15000</value>\n</property>\n\n<property>\n  <name>mr3.container.command.num.waits.in.reserved</name>\n
    \ <value>360</value>\n  <description>\n    Ensure mr3.container.command.num.waits.in.reserved
    * 1 second > mr3.k8s.pod.creation.timeout.ms. \n  </description>\n</property>\n\n<property>\n
    \ <name>mr3.k8s.pod.creation.timeout.ms</name>\n  <value>300000</value>\n  <description>\n
    \   The default value of 30 seconds is too short on EKS.\n  </description>\n</property>\n\n<property>\n
    \ <name>mr3.k8s.pod.master.node.selector</name>\n  <value></value>\n</property>\n\n<property>\n
    \ <name>mr3.k8s.pod.master.toleration.specs</name>\n  <value></value>\n</property>\n\n<property>\n
    \ <name>mr3.k8s.master.pod.affinity.match.label</name>\n  <value>hivemr3_app=hiveserver2</value>\n</property>\n\n<property>\n
    \ <name>mr3.k8s.pod.worker.node.selector</name>\n  <value></value>\n</property>\n\n<property>\n
    \ <name>mr3.k8s.pod.worker.toleration.specs</name>\n  <value></value>\n</property>\n\n<property>\n
    \ <name>mr3.k8s.pod.image.pull.policy</name>\n  <value>Always</value>\n</property>\n\n<property>\n
    \ <name>mr3.k8s.pod.image.pull.secrets</name>\n  <value></value>\n</property>\n\n<property>\n
    \ <name>mr3.k8s.host.aliases</name>\n  <value>red0=1.1.1.1</value>\n</property>\n\n<property>\n
    \ <name>mr3.k8s.pod.master.emptydirs</name>\n  <value>/opt/mr3-run/work-local-dir</value>\n</property>\n\n<property>\n
    \ <name>mr3.k8s.pod.master.hostpaths</name>\n  <value></value>\n</property>\n\n<!--\n<property>\n
    \ <name>mr3.k8s.pod.worker.emptydirs</name>\n  <value>/opt/mr3-run/work-local-dir</value>\n</property>\n
    -->\n\n<!-- set to /ephemeral1 with instance storage mounted on /ephemeral1 for
    worker Pod on AWS EKS -->\n<property>\n  <name>mr3.k8s.pod.worker.hostpaths</name>\n
    \ <value>/data1/k8s,/data2/k8s,/data3/k8s</value>\n</property>\n\n<property>\n  <name>mr3.k8s.pod.worker.additional.hostpaths</name>\n
    \ <value></value>\n</property>\n\n<property>\n  <name>mr3.k8s.master.local.dir.persistentvolumes</name>\n
    \ <value></value>\n</property>\n\n<!--\n<property>\n  <name>mr3.k8s.worker.local.dir.persistentvolumes</name>\n
    \ <value>/opt/mr3-run/disk1,/opt/mr3-run/disk2</value>\n</property>\n -->\n\n<property>\n
    \ <name>mr3.k8s.local.dir.persistentvolume.storageclass</name>\n  <value>gp2</value>\n</property>\n\n<property>\n
    \ <name>mr3.k8s.local.dir.persistentvolume.storage</name>\n  <value>2Gi</value>\n</property>\n\n<property>\n
    \ <name>mr3.k8s.readiness.probe.initial.delay.secs</name>\n  <value>15</value>\n</property>\n\n<property>\n
    \ <name>mr3.k8s.readiness.probe.period.secs</name>\n  <value>15</value>\n</property>\n\n<property>\n
    \ <name>mr3.k8s.liveness.probe.initial.delay.secs</name>\n  <value>30</value>\n</property>\n\n<property>\n
    \ <name>mr3.k8s.liveness.probe.period.secs</name>\n  <value>30</value>\n</property>\n\n<property>\n
    \ <name>mr3.app.history.logging.enabled</name>\n  <value>false</value>\n</property>\n\n<property>\n
    \ <name>mr3.dag.history.logging.enabled</name>\n  <value>false</value>\n</property>\n\n<property>\n
    \ <name>mr3.task.history.logging.enabled</name>\n  <value>false</value>\n</property>\n\n<property>\n
    \ <name>mr3.container.task.failure.num.sleeps</name>\n  <value>0</value>\n</property>\n\n<!--
    auto-scaling -->\n\n<!-- set to true on AWS EKS -->\n<property>\n  <name>mr3.enable.auto.scaling</name>\n
    \ <value>false</value>\n</property>\n\n<property>\n  <name>mr3.memory.usage.check.scheme</name>\n
    \ <value>average</value>\n</property>\n\n<property>\n  <name>mr3.auto.scale.out.threshold.percent</name>\n
    \ <value>80</value>\n</property>\n\n<property>\n  <name>mr3.auto.scale.in.threshold.percent</name>\n
    \ <value>50</value>\n</property>\n\n<property>\n  <name>mr3.memory.usage.check.window.length.secs</name>\n
    \ <value>600</value>\n</property>\n\n<property>\n  <name>mr3.check.memory.usage.event.interval.secs</name>\n
    \ <value>10</value>\n</property>\n\n<property>\n  <name>mr3.auto.scale.out.grace.period.secs</name>\n
    \ <value>300</value>\n</property>\n\n<property>\n  <name>mr3.auto.scale.in.delay.after.scale.out.secs</name>\n
    \ <value>300</value>\n</property>\n\n<property>\n  <name>mr3.auto.scale.in.grace.period.secs</name>\n
    \ <value>90</value>\n</property>\n\n<property>\n  <name>mr3.auto.scale.in.wait.dag.finished</name>\n
    \ <value>true</value>\n</property>\n\n<property>\n  <name>mr3.auto.scale.out.num.initial.containers</name>\n
    \ <value>4</value>\n</property>\n\n<property>\n  <name>mr3.auto.scale.out.num.increment.containers</name>\n
    \ <value>1</value>\n</property>\n\n<property>\n  <name>mr3.auto.scale.in.num.decrement.hosts</name>\n
    \ <value>1</value>\n</property>\n\n<property>\n  <name>mr3.auto.scale.in.min.hosts</name>\n
    \ <value>1</value>\n</property>\n\n<!-- set to false when using S3 instead of PersistentVolume
    on AWS EKS -->\n<property>\n  <name>mr3.am.staging.dir.check.ownership.permission</name>\n
    \ <value>false</value>\n</property>\n\n<property>\n  <name>mr3.am.task.concurrent.run.threshold.percent</name>\n
    \ <value>100</value>\n</property>\n\n<property>\n  <name>mr3.am.task.concurrent.run.enable.root.vertex</name>\n
    \ <value>true</value>\n</property>\n\n<!-- Fargate does not support privileged init
    containers -->\n<property>\n  <name>mr3.k8s.pod.worker.security.context.sysctls</name>\n
    \ <value>net.core.somaxconn=16384</value>\n</property>\n\n<!-- Fargate does not
    support privileged init containers -->\n<property>\n  <name>mr3.k8s.pod.worker.init.container.command</name>\n
    \ <value></value>\n</property>\n\n<property>\n  <name>mr3.k8s.pod.worker.init.container.image</name>\n
    \ <value>busybox</value>\n</property>\n\n<property>\n  <name>mr3.k8s.shufflehandler.process.memory.mb</name>\n
    \ <value>2048</value>\n</property>\n\n<property>\n  <name>mr3.k8s.shuffle.process.ports</name>\n
    \ <value>15500,15510,15520,15530,15540,15550,15560,15570</value>\n</property>\n\n<!--
    Prometheus -->\n\n<property>\n  <name>mr3.prometheus.enable.metrics</name>\n  <value>false</value>\n</property>\n\n<property>\n
    \ <name>mr3.prometheus.enable.jvm.metrics</name>\n  <value>false</value>\n</property>\n\n<property>\n
    \ <name>mr3.k8s.master.pod.additional.labels</name>\n  <value>hivemr3_aux=prometheus</value>\n</property>\n\n<property>\n
    \ <name>mr3.prometheus.worker.enable.metrics</name>\n  <value>false</value>\n</property>\n\n<property>\n
    \ <name>mr3.prometheus.worker.enable.jvm.metrics</name>\n  <value>true</value>\n</property>\n\n<property>\n
    \ <name>mr3.prometheus.worker.httpserver.port</name>\n  <value>9890</value>\n</property>\n\n<property>\n
    \ <name>dfs.namenode.delegation.token.renew-interval</name>\n  <value>86400000</value>\n
    \ <description>\n    Internally used by mr3.common.security.TokenRenewer when Kerberos
    token renewal is enabled inside DAGAppMaster and ContainerWorkers.\n    Replaces
    org.apache.hadoop.hdfs.DFSConfigKeys.DFS_NAMENODE_DELEGATION_TOKEN_RENEW_INTERVAL_KEY.\n
    \ </description>\n</property>\n\n</configuration>\n"
  ranger-hive-audit.xml: "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!--\n
    \ Licensed under the Apache License, Version 2.0 (the \"License\");\n  you may not
    use this file except in compliance with the License.\n  You may obtain a copy of
    the License at\n\n      http://www.apache.org/licenses/LICENSE-2.0\n\n  Unless required
    by applicable law or agreed to in writing, software\n  distributed under the License
    is distributed on an \"AS IS\" BASIS,\n  WITHOUT WARRANTIES OR CONDITIONS OF ANY
    KIND, either express or implied.\n  See the License for the specific language governing
    permissions and\n  limitations under the License.\n-->\n<?xml-stylesheet type=\"text/xsl\"
    href=\"configuration.xsl\"?><configuration xmlns:xi=\"http://www.w3.org/2001/XInclude\">\n
    \ <property>\n    <name>xasecure.audit.is.enabled</name>\n    <value>true</value>\n
    \ </property>\t\n\n  <!-- Ranger audit provider configuration -->\n  <property>\n
    \   <name>xasecure.audit.destination.solr</name>\n    <value>true</value>\n  </property>\n\n
    \ <property>\n    <name>xasecure.audit.destination.solr.urls</name>\n    <value>http://red0:6083/solr/ranger_audits</value>\n
    \ </property>\n\n  <property>\n    <name>xasecure.audit.destination.solr.batch.filespool.dir</name>\n
    \   <value>/opt/mr3-run/work-dir/hive/hive_audit_solr_spool</value>\n  </property>\n\n</configuration>\n"
  ranger-hive-policymgr-ssl.xml: "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!--\n
    \ Licensed under the Apache License, Version 2.0 (the \"License\");\n  you may not
    use this file except in compliance with the License.\n  You may obtain a copy of
    the License at\n\n      http://www.apache.org/licenses/LICENSE-2.0\n\n  Unless required
    by applicable law or agreed to in writing, software\n  distributed under the License
    is distributed on an \"AS IS\" BASIS,\n  WITHOUT WARRANTIES OR CONDITIONS OF ANY
    KIND, either express or implied.\n  See the License for the specific language governing
    permissions and\n  limitations under the License.\n-->\n<?xml-stylesheet type=\"text/xsl\"
    href=\"configuration.xsl\"?><configuration xmlns:xi=\"http://www.w3.org/2001/XInclude\">\n
    \ <!--  The following properties are used for 2-way SSL client server validation
    -->\n  <property>\n    <name>xasecure.policymgr.clientssl.keystore</name>\n    <value>/opt/mr3-run/key/hivemr3-ssl-certificate.jks</value>\n
    \   <description> \n      Java Keystore files \n    </description>\n  </property>\n
    \ <property>\n    <name>xasecure.policymgr.clientssl.keystore.type</name>\n    <value>jks</value>\n
    \ </property>\n  <property>\n    <name>xasecure.policymgr.clientssl.keystore.credential.file</name>\n
    \   <value>jceks://file/opt/mr3-run/key/hivemr3-ssl-certificate.jceks</value>\n
    \   <description> \n      java keystore credential file\n    </description>\n  </property>\n
    \ <property>\n    <name>xasecure.policymgr.clientssl.truststore</name>\n    <value>/opt/mr3-run/key/hivemr3-ssl-certificate.jks</value>\n
    \   <description>\n      java truststore file\n    </description>\n  </property>\n
    \ <property>\n    <name>xasecure.policymgr.clientssl.truststore.type</name>\n    <value>jks</value>\n
    \ </property>\n  <property>\n    <name>xasecure.policymgr.clientssl.truststore.credential.file</name>\n
    \   <value>jceks://file/opt/mr3-run/key/hivemr3-ssl-certificate.jceks</value>\n
    \   <description> \n      java truststore credential file\n    </description>\n
    \ </property>\n</configuration>\n"
  ranger-hive-security.xml: |
    <?xml version="1.0" encoding="UTF-8" standalone="no"?>
    <!--
      Licensed under the Apache License, Version 2.0 (the "License");
      you may not use this file except in compliance with the License.
      You may obtain a copy of the License at
  
          http://www.apache.org/licenses/LICENSE-2.0
  
      Unless required by applicable law or agreed to in writing, software
      distributed under the License is distributed on an "AS IS" BASIS,
      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
      See the License for the specific language governing permissions and
      limitations under the License.
    -->
    <?xml-stylesheet type="text/xsl" href="configuration.xsl"?><configuration xmlns:xi="http://www.w3.org/2001/XInclude">
      <property>
        <name>ranger.plugin.hive.service.name</name>
        <value>INDIGO_hive</value>
        <description>
          Name of the Ranger service containing policies for this YARN instance
        </description>
      </property>
  
      <property>
        <name>ranger.plugin.hive.policy.source.impl</name>
        <value>org.apache.ranger.admin.client.RangerAdminRESTClient</value>
        <description>
          Class to retrieve policies from the source
        </description>
      </property>
  
      <property>
        <name>ranger.plugin.hive.policy.rest.url</name>
        <value>http://red0:6080</value>
        <description>
          URL to Ranger Admin (https://red0:6182 when using SSL)
        </description>
      </property>
  
      <property>
        <name>ranger.plugin.hive.policy.rest.ssl.config.file</name>
        <value>/opt/mr3-run/conf/ranger-hive-policymgr-ssl.xml</value>
        <description>
          Path to the file containing SSL details to contact Ranger Admin
        </description>
      </property>
  
      <property>
        <name>ranger.plugin.hive.policy.pollIntervalMs</name>
        <value>30000</value>
        <description>
          How often to poll for changes in policies?
        </description>
      </property>
  
      <property>
        <name>ranger.plugin.hive.policy.cache.dir</name>
        <value>/opt/mr3-run/hiveserver2-ranger-policycache</value>
        <description>
          Directory where Ranger policies are cached after successful retrieval from the source
        </description>
      </property>
  
      <property>
        <name>xasecure.hive.update.xapolicies.on.grant.revoke</name>
        <value>true</value>
        <description>Should Hive plugin update Ranger policies for updates to permissions done using GRANT/REVOKE?</description>
      </property>
  
      <property>
        <name>ranger.plugin.hive.policy.rest.client.connection.timeoutMs</name>
        <value>120000</value>
        <description>
          RangerRestClient Connection Timeout in Milli Seconds
        </description>
      </property>
  
      <property>
        <name>ranger.plugin.hive.policy.rest.client.read.timeoutMs</name>
        <value>30000</value>
        <description>
          RangerRestClient read Timeout in Milli Seconds
        </description>
      </property>
    </configuration>
  tez-site.xml: "<configuration>\n\n<property>\n  <name>tez.counters.max</name>\n  <value>10000</value>\n</property>\n\n<property>\n
    \ <name>tez.counters.max.groups</name>\n  <value>3000</value>\n</property>\n\n<property>\n
    \ <name>tez.grouping.max-size</name>\n  <value>1073741824</value>\n</property>\n
    \n<property>\n  <name>tez.grouping.min-size</name>\n  <value>16777216</value>\n</property>\n
    \n<property>\n  <name>tez.grouping.split-waves</name>\n  <value>1.7</value>\n</property>\n
    \n<property>\n  <name>tez.runtime.compress</name>\n  <value>true</value>\n</property>\n
    \n<property>\n  <name>tez.runtime.compress.codec</name>\n  <value>org.apache.hadoop.io.compress.SnappyCodec</value>\n</property>\n\n<property>\n
    \ <name>tez.runtime.io.sort.mb</name>\n  <value>1040</value>\n</property>\n\n<property>\n
    \ <name>tez.runtime.optimize.local.fetch</name>\n  <value>true</value>\n</property>\n\n<property>\n
    \ <name>tez.runtime.pipelined.sorter.sort.threads</name>\n  <value>2</value>\n</property>\n\n<property>\n
    \ <name>tez.runtime.sorter.class</name>\n  <value>PIPELINED</value>\n</property>\n\n<property>\n
    \ <name>tez.runtime.unordered.output.buffer.size-mb</name>\n  <value>307</value>\n</property>\n\n<!--
    configurable in Hive (Cf. HIVE-24485)  --> \n<property>\n  <name>tez.shuffle-vertex-manager.max-src-fraction</name>\n
    \ <value>0.4</value>\n</property>\n<property>\n  <name>tez.shuffle-vertex-manager.min-src-fraction</name>\n
    \ <value>0.2</value>\n</property>\n\n<property>\n  <name>tez.runtime.pipelined.sorter.lazy-allocate.memory</name>\n
    \ <value>true</value>\n</property>\n\n<property>\n  <name>tez.runtime.shuffle.parallel.copies</name>\n
    \ <value>20</value>\n</property>\n\n<!-- MR3 0.4 -->\n\n<property>\n  <name>tez.runtime.pipelined.sorter.use.soft.reference</name>\n
    \ <value>false</value>\n</property>\n\n<property>\n  <name>tez.shuffle-vertex-manager.enable.auto-parallel</name>\n
    \ <value>true</value>\n</property>\n\n<!-- to disable auto parallelism, set tez.shuffle-vertex-manager.auto-parallel.min.num.tasks
    to a value larger than hive.exec.reducers.max in hive-site.xml -->\n<property>\n
    \ <name>tez.shuffle-vertex-manager.auto-parallel.min.num.tasks</name>\n  <value>251</value>\n</property>\n\n<property>\n
    \ <name>tez.shuffle-vertex-manager.auto-parallel.max.reduction.percentage</name>\n
    \ <value>50</value>\n</property>\n\n<property>\n  <name>tez.shuffle-vertex-manager.use-stats-auto-parallelism</name>\n
    \ <value>true</value>\n</property>\n\n<property>\n  <name>tez.shuffle.vertex.manager.auto.parallelism.min.percent</name>\n
    \ <value>0</value>\n</property>\n\n<!-- MR3 0.5 -->\n\n<property>\n  <name>tez.am.shuffle.auxiliary-service.id</name>\n
    \ <value>tez_shuffle</value>\n</property>\n\n<property>\n  <name>tez.shuffle.port</name>\n
    \ <value>15551</value>\n</property>\n\n<property>\n  <name>tez.runtime.shuffle.keep-alive.enabled</name>\n
    \ <value>true</value>\n</property>\n\n<property>\n  <name>tez.shuffle.connection-keep-alive.enable</name>\n
    \ <value>true</value>\n</property>\n\n<property>\n  <name>tez.shuffle.max.threads</name>\n
    \ <value>20</value>\n  <description>\n    Set to 'total number of threads for shuffle
    handlers / mr3.use.daemon.shufflehandler'\n  </description>\n</property>\n\n<property>\n
    \ <name>tez.shuffle.listen.queue.size</name>\n  <value>16384</value>\n</property>\n\n<property>\n
    \ <name>tez.shuffle.mapoutput-info.meta.cache.size</name>\n  <value>10000</value>\n</property>\n\n<!--
    MR3 0.7 -->\n\n<property>\n  <name>tez.runtime.pipelined-shuffle.enabled</name>\n
    \ <value>false</value>\n</property>\n\n<property>\n  <name>tez.runtime.enable.final-merge.in.output</name>\n
    \ <value>true</value>\n</property>\n\n<property>\n  <name>tez.runtime.shuffle.memory-to-memory.enable</name>\n
    \ <value>false</value>\n</property>\n\n<property>\n  <name>tez.runtime.task.input.post-merge.buffer.percent</name>\n
    \ <value>0.0</value>\n</property>\n\n<property>\n  <name>tez.runtime.shuffle.src-attempt.abort.limit</name>\n
    \ <value>3</value>\n</property>\n\n<!-- MR3 0.8 -->\n\n<property>\n  <name>tez.runtime.shuffle.connect.timeout</name>\n
    \ <value>7500</value>\n  <description>\n    Set to 2500 in order not to retry when
    a connection failure occurs.\n  </description>\n</property>\n\n<!-- MR3 1.1 -->\n\n<property>\n
    \ <name>tez.runtime.local.fetch.compare.port</name>\n  <value>false</value>\n  <!--
    irrelevant on Kubernetes because a logical host runs only one ContainerWorker -->\n</property>\n\n<!--
    MR3 1.3 -->\n\n<property>\n  <name>tez.grouping.node.local.only</name>\n  <value>true</value>\n
    \ <!-- do not use racks on Kubernetes -->\n</property>\n\n<!-- MR3 1.8 -->\n\n<property>\n
    \ <name>tez.shuffle.indexcache.mb</name>\n  <value>20</value>\n</property>\n\n<property>\n
    \ <name>tez.shuffle.indexcache.share</name>\n  <value>true</value>\n</property>\n\n<!--
    MR3 1.9 -->\n\n<property>\n  <name>tez.runtime.use.free.memory.fetched.input</name>\n
    \ <value>true</value>\n</property>\n\n<!-- CartesianProductVertexManager -->\n\n<property>\n
    \ <name>tez.cartesian-product.grouping-fraction</name>\n  <value>0.75</value>\n</property>\n\n<property>\n
    \ <name>tez.cartesian-product.min-ops-per-worker</name>\n  <value>1000000</value>\n</property>\n\n<!--
    Secure shuffle -->\n<!-- \n  if hadoop.security.credential.provider.path is not
    set in core-site.xml,\n    passwords are read dirctly from tez-site.xml in text.\n
    \ if hadoop.security.credential.provider.path is set in core-site.xml,\n    passwords
    are read from the credential file.\n -->\n\n<property>\n  <name>tez.runtime.shuffle.ssl.enable</name>\n
    \ <value>false</value>\n</property>\n\n<property>\n  <name>ssl.server.truststore.location</name>\n
    \ <value>/opt/mr3-run/key/mr3-truststore.jks</value>\n</property>\n\n<property>\n
    \ <name>ssl.server.truststore.password</name>\n  <value>truststore_password</value>\n</property>\n\n<property>\n
    \ <name>ssl.server.keystore.location</name>\n  <value>/opt/mr3-run/key/mr3-keystore.jks</value>\n</property>\n\n<property>\n
    \ <name>ssl.server.keystore.password</name>\n  <value>keystore_password</value>\n</property>\n\n<property>\n
    \ <name>ssl.server.keystore.keypassword</name>\n  <value>key_password</value>\n</property>\n\n<property>\n
    \ <name>ssl.client.truststore.location</name>\n  <value>/opt/mr3-run/key/mr3-truststore.jks</value>\n</property>\n\n<property>\n
    \ <name>ssl.client.truststore.password</name>\n  <value>truststore_password</value>\n</property>\n\n</configuration>\n"
  yarn-site.xml: |+
    <configuration>
  
    <property>
      <name>yarn.resourcemanager.principal</name>
      <value>rm/red0@RED</value>
    </property>
  
    <property>
      <name>yarn.timeline-service.enabled</name>
      <value>false</value>
    </property>
  
    <property>
      <name>yarn.timeline-service.version</name>
      <value>1.0f</value>
    </property>
  
    <property>
      <name>yarn.http.policy</name>
      <value>HTTP_ONLY</value>
    </property>
  
    <property>
      <name>yarn.timeline-service.webapp.address</name>
      <value>timeline.hivemr3.svc.cluster.local:9188</value>
    </property>
  
    <property>
      <name>yarn.timeline-service.webapp.https.address</name>
      <value>timeline.hivemr3.svc.cluster.local:9190</value>
    </property>
  
    </configuration>
---
# Source: hive/templates/workdir-pv.yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: workdir-pv
  labels:
    hivemr3_app: hiveserver2
spec:
  capacity:
    storage: 20Gi
  accessModes:
    - ReadWriteMany
  persistentVolumeReclaimPolicy: Delete
  nfs:
    server: 10.51.199.33
    path: /
---
# Source: hive/templates/workdir-pvc.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  #namespace: hivemr3
  name: workdir-pvc
spec:
  resources:
    requests:
      storage: 5Gi
  accessModes:
  - ReadWriteMany
  storageClassName: ""
  selector:
    matchLabels:
      hivemr3_app: hiveserver2
---
# Source: hive/templates/cluster-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: node-reader
rules:
- apiGroups: [""]
  resources: ["nodes"]
  verbs: ["get", "watch", "list"]
---
# Source: hive/templates/cluster-role-binding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: hive-clusterrole-binding
roleRef:
  kind: ClusterRole
  name: node-reader
  apiGroup: rbac.authorization.k8s.io
subjects:
- kind: ServiceAccount
  name: hive-service-account
  namespace: default
---
# Source: hive/templates/master-cluster-role-binding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: master-clusterrole-binding
roleRef:
  kind: ClusterRole
  name: node-reader
  apiGroup: rbac.authorization.k8s.io
subjects:
- kind: ServiceAccount
  name: master-service-account
  namespace: default
---
# Source: hive/templates/hive-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  #namespace: hivemr3
  name: hive-role
rules:
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "watch", "list", "create", "delete"]
- apiGroups: ["extensions", "apps"]
  resources: ["deployments"]
  verbs: ["get", "watch", "list", "create", "delete"]
- apiGroups: [""]
  resources: ["configmaps"]
  verbs: ["get", "create", "update", "delete"]
- apiGroups: [""]
  resources: ["secrets"]
  verbs: ["get"]
- apiGroups: [""]
  resources: ["services"]
  verbs: ["get", "list", "create", "delete"]
---
# Source: hive/templates/master-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: default
  name: master-role
rules:
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "watch", "list", "create", "delete"]
- apiGroups: [""]
  resources: ["configmaps"]
  verbs: ["get", "create", "update", "delete"]
- apiGroups: [""]
  resources: ["secrets"]
  verbs: ["get"]
- apiGroups: [""]
  resources: ["services"]
  verbs: ["get", "list", "create", "delete"]
---
# Source: hive/templates/worker-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: default
  name: worker-role
rules:
- apiGroups: [""]
  resources: ["configmaps"]
  verbs: ["get"]
- apiGroups: [""]
  resources: ["secrets"]
  verbs: ["get"]
---
# Source: hive/templates/hive-role-binding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: hive-role-binding
roleRef:
  kind: Role
  name: hive-role
  apiGroup: rbac.authorization.k8s.io
subjects:
- kind: ServiceAccount
  name: hive-service-account
  namespace: default
---
# Source: hive/templates/master-role-binding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: master-role-binding
roleRef:
  kind: Role
  name: master-role
  apiGroup: rbac.authorization.k8s.io
subjects:
- kind: ServiceAccount
  name: master-service-account
  namespace: default
---
# Source: hive/templates/worker-role-binding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: worker-role-binding
roleRef:
  kind: Role
  name: worker-role
  apiGroup: rbac.authorization.k8s.io
subjects:
- kind: ServiceAccount
  name: worker-service-account
  namespace: default
---
# Source: hive/templates/hiveserver2-service.yaml
apiVersion: v1
kind: Service
metadata:
  #namespace: hivemr3
  name: hiveserver2
spec:
  type: LoadBalancer
  ports:
  - protocol: TCP
    port: 9852
    targetPort: 9852
    name: thrift
  - protocol: TCP
    port: 10001
    targetPort: 10001
    name: http
  selector:
    hivemr3_app: hiveserver2
  externalIPs:
  - 1.1.1.1
---
# Source: hive/templates/metastore-service.yaml
apiVersion: v1
kind: Service
metadata:
  #namespace: hivemr3
  name: metastore
spec:
  clusterIP: None
  selector:
    hivemr3_app: metastore
  ports:
  - name: tcp
    port: 9850
---
# Source: hive/templates/hive.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  #namespace: hivemr3
  name: hivemr3-hiveserver2
spec:
  replicas: 1
  selector:
    matchLabels:
      hivemr3_hive_source: hivesrc3
      hivemr3_app: hiveserver2
  template:
    metadata:
      #namespace: hivemr3
      name: hivemr3-hiveserver2
      labels:
        hivemr3_hive_source: hivesrc3
        hivemr3_app: hiveserver2
        mr3-pod-role: master-role
    spec:
      serviceAccountName: hive-service-account
      restartPolicy: Always
      hostAliases:
      - ip: 1.1.1.1
        hostnames:
        - red0
      affinity:
        podAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              topologyKey: kubernetes.io/hostname
              labelSelector:
                matchLabels:
                  hivemr3_app: metastore
      containers:
      - image: mr3project/hive3:1.9
        command: ["/opt/mr3-run/hive/hiveserver2-service.sh"]
        args: ["start", "--kubernetes"]
        imagePullPolicy: IfNotPresent
        name: hiveserver2
        env:
        - name: CLIENT_TO_AM_TOKEN_KEY
          valueFrom:
            configMapKeyRef:
              name: client-am-config
              key: key
        - name: MR3_APPLICATION_ID_TIMESTAMP
          valueFrom:
            configMapKeyRef:
              name: client-am-config
              key: timestamp
        - name: MR3_SHARED_SESSION_ID
          valueFrom:
            configMapKeyRef:
              name: client-am-config
              key: mr3sessionid
        - name: ATS_SECRET_KEY
          valueFrom:
            configMapKeyRef:
              name: client-am-config
              key: ats-secret-key
        resources:
          requests:
            cpu: 2
            memory: 1Gi
          limits:
            cpu: 2
            memory: 1Gi
        ports:
        - containerPort: 9852
          protocol: TCP
        - containerPort: 10001
          protocol: TCP
        readinessProbe:
          tcpSocket:
            port: 9852
          initialDelaySeconds: 30
          periodSeconds: 60
        livenessProbe:
          tcpSocket:
            port: 9852
          initialDelaySeconds: 30
          periodSeconds: 60
        volumeMounts:
        - name: env-k8s-volume
          mountPath: /opt/mr3-run/env.sh
          subPath: env.sh
        - name: env-secret-k8s-volume
          mountPath: /opt/mr3-run/env-secret.sh
          subPath: env-secret.sh
        - name: conf-k8s-volume
          mountPath: /opt/mr3-run/conf
          readOnly: true
        - name: key-k8s-volume
          mountPath: /opt/mr3-run/key
          readOnly: true
        - name: am-local-k8s-volume
          mountPath: /opt/mr3-run/am-local-dir
        - name: work-dir-volume
          mountPath: /opt/mr3-run/work-dir
        - name: hiveserver2-ranger-policy-k8s-volume
          mountPath: /opt/mr3-run/hiveserver2-ranger-policycache
      volumes:
      - name: env-k8s-volume
        configMap:
          name: env-configmap
      - name: env-secret-k8s-volume
        secret:
          secretName: env-secret
      - name: conf-k8s-volume
        configMap:
          name: hivemr3-conf-configmap
      - name: key-k8s-volume
        secret:
          secretName: hivemr3-keytab-secret
      - name: am-local-k8s-volume
        emptyDir: {}
      - name: work-dir-volume
        persistentVolumeClaim:
          claimName: workdir-pvc
      - name: hiveserver2-ranger-policy-k8s-volume
        emptyDir: {}
---
# Source: hive/templates/metastore.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  #namespace: hivemr3
  name: hivemr3-metastore
spec:
  serviceName: metastore
  replicas: 1
  selector:
    matchLabels:
      hivemr3_hive_source: hivesrc3
      hivemr3_app: metastore
  template:
    metadata:
      #namespace: hivemr3
      name: hivemr3-metastore
      labels:
        hivemr3_hive_source: hivesrc3
        hivemr3_app: metastore
        mr3-pod-role: master-role
    spec:
      serviceAccountName: hive-service-account
      restartPolicy: Always
      affinity:
        # nodeAffinity:
        #   requiredDuringSchedulingIgnoredDuringExecution:
        #     nodeSelectorTerms:
        #     - matchExpressions:
        #       - key: roles
        #         operator: In
        #         values:
        #         - "masters"
        podAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              topologyKey: kubernetes.io/hostname
              labelSelector:
                matchLabels:
                  hivemr3_app: ranger
      hostAliases:
      - ip: 1.1.1.1
        hostnames:
        - red0
      containers:
      - image: mr3project/hive3:1.9
        command: ["/opt/mr3-run/hive/metastore-service.sh"]
        args: ["start", "--init-schema", "--kubernetes"]
        imagePullPolicy: IfNotPresent
        name: metastore
        env:
        - name: CLIENT_TO_AM_TOKEN_KEY
          valueFrom:
            configMapKeyRef:
              name: client-am-config
              key: key
        - name: MR3_APPLICATION_ID_TIMESTAMP
          valueFrom:
            configMapKeyRef:
              name: client-am-config
              key: timestamp
        - name: MR3_SHARED_SESSION_ID
          valueFrom:
            configMapKeyRef:
              name: client-am-config
              key: mr3sessionid
        - name: ATS_SECRET_KEY
          valueFrom:
            configMapKeyRef:
              name: client-am-config
              key: ats-secret-key
        resources:
          requests:
            cpu: 1
            memory: 8Gi
          limits:
            cpu: 1
            memory: 8Gi
        ports:
        - containerPort: 9850
          protocol: TCP
        # uncomment to use readiness/liveness probes
        # readinessProbe:
        #   tcpSocket:
        #     port: 9850
        #   initialDelaySeconds: 30
        #   periodSeconds: 60
        # livenessProbe:
        #   tcpSocket:
        #     port: 9850
        #   initialDelaySeconds: 30
        #   periodSeconds: 60
        volumeMounts:
        - name: env-k8s-volume
          mountPath: /opt/mr3-run/env.sh
          subPath: env.sh
        - name: env-secret-k8s-volume
          mountPath: /opt/mr3-run/env-secret.sh
          subPath: env-secret.sh
        - name: conf-k8s-volume
          mountPath: /opt/mr3-run/conf
          readOnly: true
        - name: key-k8s-volume
          mountPath: /opt/mr3-run/key
          readOnly: true
        - name: work-dir-volume
          mountPath: /opt/mr3-run/work-dir
        - name: work-dir-volume
          mountPath: /opt/mr3-run/lib
          subPath: lib
      volumes:
      - name: env-k8s-volume
        configMap:
          name: env-configmap
      - name: env-secret-k8s-volume
        secret:
          secretName: env-secret
      - name: conf-k8s-volume
        configMap:
          name: hivemr3-conf-configmap
      - name: key-k8s-volume
        secret:
          secretName: hivemr3-keytab-secret
      - name: work-dir-volume
        persistentVolumeClaim:
          claimName: workdir-pvc
